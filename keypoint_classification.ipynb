{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                860       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,103\n",
      "Trainable params: 1,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 1/27 [>.............................] - ETA: 16s - loss: 1.2061 - accuracy: 0.3828\n",
      "Epoch 1: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 1s 9ms/step - loss: 1.1500 - accuracy: 0.3461 - val_loss: 1.0618 - val_accuracy: 0.4331\n",
      "Epoch 2/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 1.0656 - accuracy: 0.3906\n",
      "Epoch 2: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 1.0704 - accuracy: 0.4004 - val_loss: 1.0372 - val_accuracy: 0.4519\n",
      "Epoch 3/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 1.0278 - accuracy: 0.4609\n",
      "Epoch 3: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.4414 - val_loss: 1.0069 - val_accuracy: 0.4924\n",
      "Epoch 4/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 1.0221 - accuracy: 0.5234\n",
      "Epoch 4: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.0172 - accuracy: 0.4900 - val_loss: 0.9725 - val_accuracy: 0.6496\n",
      "Epoch 5/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.9757 - accuracy: 0.5469\n",
      "Epoch 5: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.9946 - accuracy: 0.5157 - val_loss: 0.9302 - val_accuracy: 0.6568\n",
      "Epoch 6/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.9769 - accuracy: 0.5234\n",
      "Epoch 6: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.9680 - accuracy: 0.5289 - val_loss: 0.8967 - val_accuracy: 0.6658\n",
      "Epoch 7/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.9343 - accuracy: 0.5391\n",
      "Epoch 7: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.9414 - accuracy: 0.5646 - val_loss: 0.8521 - val_accuracy: 0.7269\n",
      "Epoch 8/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.9325 - accuracy: 0.5391\n",
      "Epoch 8: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.9033 - accuracy: 0.5781 - val_loss: 0.8028 - val_accuracy: 0.7358\n",
      "Epoch 9/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.9926 - accuracy: 0.4922\n",
      "Epoch 9: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8887 - accuracy: 0.5871 - val_loss: 0.7632 - val_accuracy: 0.7951\n",
      "Epoch 10/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.8398 - accuracy: 0.6250\n",
      "Epoch 10: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.8592 - accuracy: 0.6233 - val_loss: 0.7252 - val_accuracy: 0.7987\n",
      "Epoch 11/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.8313 - accuracy: 0.5703\n",
      "Epoch 11: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8310 - accuracy: 0.6347 - val_loss: 0.6757 - val_accuracy: 0.8122\n",
      "Epoch 12/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.7654 - accuracy: 0.6719\n",
      "Epoch 12: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.8002 - accuracy: 0.6401 - val_loss: 0.6363 - val_accuracy: 0.8266\n",
      "Epoch 13/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.7840 - accuracy: 0.6797\n",
      "Epoch 13: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.7810 - accuracy: 0.6521 - val_loss: 0.5949 - val_accuracy: 0.8580\n",
      "Epoch 14/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.7335 - accuracy: 0.7031\n",
      "Epoch 14: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.6659 - val_loss: 0.5695 - val_accuracy: 0.8751\n",
      "Epoch 15/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.8052 - accuracy: 0.6172\n",
      "Epoch 15: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.6803 - val_loss: 0.5336 - val_accuracy: 0.8904\n",
      "Epoch 16/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6378 - accuracy: 0.7422\n",
      "Epoch 16: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7159 - accuracy: 0.6895 - val_loss: 0.5074 - val_accuracy: 0.9030\n",
      "Epoch 17/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6110 - accuracy: 0.8047\n",
      "Epoch 17: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.7144 - val_loss: 0.4763 - val_accuracy: 0.9173\n",
      "Epoch 18/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6801 - accuracy: 0.7188\n",
      "Epoch 18: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.7252 - val_loss: 0.4570 - val_accuracy: 0.9182\n",
      "Epoch 19/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.7217 - accuracy: 0.7188\n",
      "Epoch 19: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.7207 - val_loss: 0.4356 - val_accuracy: 0.9191\n",
      "Epoch 20/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6794 - accuracy: 0.7422\n",
      "Epoch 20: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7234 - val_loss: 0.4164 - val_accuracy: 0.9290\n",
      "Epoch 21/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6820 - accuracy: 0.7031\n",
      "Epoch 21: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.7264 - val_loss: 0.4018 - val_accuracy: 0.9344\n",
      "Epoch 22/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5549 - accuracy: 0.8047\n",
      "Epoch 22: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7525 - val_loss: 0.3859 - val_accuracy: 0.9407\n",
      "Epoch 23/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5112 - accuracy: 0.8125\n",
      "Epoch 23: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.7483 - val_loss: 0.3686 - val_accuracy: 0.9416\n",
      "Epoch 24/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6020 - accuracy: 0.7344\n",
      "Epoch 24: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.7531 - val_loss: 0.3580 - val_accuracy: 0.9371\n",
      "Epoch 25/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5601 - accuracy: 0.7656\n",
      "Epoch 25: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.7540 - val_loss: 0.3563 - val_accuracy: 0.9452\n",
      "Epoch 26/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5619 - accuracy: 0.8203\n",
      "Epoch 26: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.7672 - val_loss: 0.3466 - val_accuracy: 0.9506\n",
      "Epoch 27/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6299 - accuracy: 0.7734\n",
      "Epoch 27: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7642 - val_loss: 0.3334 - val_accuracy: 0.9524\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4870 - accuracy: 0.8203\n",
      "Epoch 28: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7606 - val_loss: 0.3182 - val_accuracy: 0.9560\n",
      "Epoch 29/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5151 - accuracy: 0.8203\n",
      "Epoch 29: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.7705 - val_loss: 0.3103 - val_accuracy: 0.9569\n",
      "Epoch 30/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5013 - accuracy: 0.7891\n",
      "Epoch 30: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7672 - val_loss: 0.3095 - val_accuracy: 0.9542\n",
      "Epoch 31/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.6450 - accuracy: 0.7500\n",
      "Epoch 31: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7714 - val_loss: 0.2977 - val_accuracy: 0.9632\n",
      "Epoch 32/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5013 - accuracy: 0.7891\n",
      "Epoch 32: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7779 - val_loss: 0.2928 - val_accuracy: 0.9605\n",
      "Epoch 33/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5937 - accuracy: 0.7578\n",
      "Epoch 33: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7875 - val_loss: 0.2833 - val_accuracy: 0.9587\n",
      "Epoch 34/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5243 - accuracy: 0.7969\n",
      "Epoch 34: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7887 - val_loss: 0.2726 - val_accuracy: 0.9632\n",
      "Epoch 35/1000\n",
      "24/27 [=========================>....] - ETA: 0s - loss: 0.5663 - accuracy: 0.7741\n",
      "Epoch 35: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7749 - val_loss: 0.2755 - val_accuracy: 0.9668\n",
      "Epoch 36/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5525 - accuracy: 0.7422\n",
      "Epoch 36: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.8043 - val_loss: 0.2699 - val_accuracy: 0.9650\n",
      "Epoch 37/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5427 - accuracy: 0.8047\n",
      "Epoch 37: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7917 - val_loss: 0.2598 - val_accuracy: 0.9659\n",
      "Epoch 38/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5528 - accuracy: 0.7812\n",
      "Epoch 38: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7917 - val_loss: 0.2565 - val_accuracy: 0.9677\n",
      "Epoch 39/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4623 - accuracy: 0.8359\n",
      "Epoch 39: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7971 - val_loss: 0.2515 - val_accuracy: 0.9659\n",
      "Epoch 40/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5811 - accuracy: 0.8125\n",
      "Epoch 40: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7944 - val_loss: 0.2540 - val_accuracy: 0.9704\n",
      "Epoch 41/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4719 - accuracy: 0.8359\n",
      "Epoch 41: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.8016 - val_loss: 0.2451 - val_accuracy: 0.9659\n",
      "Epoch 42/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4219 - accuracy: 0.8281\n",
      "Epoch 42: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7998 - val_loss: 0.2379 - val_accuracy: 0.9712\n",
      "Epoch 43/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4470 - accuracy: 0.8594\n",
      "Epoch 43: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8058 - val_loss: 0.2326 - val_accuracy: 0.9695\n",
      "Epoch 44/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5552 - accuracy: 0.7969\n",
      "Epoch 44: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7989 - val_loss: 0.2381 - val_accuracy: 0.9677\n",
      "Epoch 45/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4057 - accuracy: 0.8359\n",
      "Epoch 45: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.8190 - val_loss: 0.2311 - val_accuracy: 0.9623\n",
      "Epoch 46/1000\n",
      "18/27 [===================>..........] - ETA: 0s - loss: 0.5150 - accuracy: 0.7951\n",
      "Epoch 46: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7968 - val_loss: 0.2328 - val_accuracy: 0.9659\n",
      "Epoch 47/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5137 - accuracy: 0.8047\n",
      "Epoch 47: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.8160 - val_loss: 0.2356 - val_accuracy: 0.9641\n",
      "Epoch 48/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5063 - accuracy: 0.8047\n",
      "Epoch 48: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8196 - val_loss: 0.2265 - val_accuracy: 0.9695\n",
      "Epoch 49/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4199 - accuracy: 0.8516\n",
      "Epoch 49: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.8163 - val_loss: 0.2213 - val_accuracy: 0.9659\n",
      "Epoch 50/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5222 - accuracy: 0.7891\n",
      "Epoch 50: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8163 - val_loss: 0.2142 - val_accuracy: 0.9721\n",
      "Epoch 51/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5030 - accuracy: 0.7969\n",
      "Epoch 51: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8250 - val_loss: 0.2139 - val_accuracy: 0.9704\n",
      "Epoch 52/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5083 - accuracy: 0.8047\n",
      "Epoch 52: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8097 - val_loss: 0.2126 - val_accuracy: 0.9712\n",
      "Epoch 53/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4670 - accuracy: 0.8047\n",
      "Epoch 53: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.8124 - val_loss: 0.2164 - val_accuracy: 0.9677\n",
      "Epoch 54/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3816 - accuracy: 0.8438\n",
      "Epoch 54: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.8043 - val_loss: 0.2153 - val_accuracy: 0.9677\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4621 - accuracy: 0.7891\n",
      "Epoch 55: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8133 - val_loss: 0.2218 - val_accuracy: 0.9704\n",
      "Epoch 56/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4413 - accuracy: 0.8438\n",
      "Epoch 56: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8106 - val_loss: 0.2072 - val_accuracy: 0.9739\n",
      "Epoch 57/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5560 - accuracy: 0.7578\n",
      "Epoch 57: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.8211 - val_loss: 0.2103 - val_accuracy: 0.9704\n",
      "Epoch 58/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4493 - accuracy: 0.8281\n",
      "Epoch 58: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8211 - val_loss: 0.2048 - val_accuracy: 0.9739\n",
      "Epoch 59/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5653 - accuracy: 0.7188\n",
      "Epoch 59: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8151 - val_loss: 0.1991 - val_accuracy: 0.9704\n",
      "Epoch 60/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4763 - accuracy: 0.8281\n",
      "Epoch 60: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8214 - val_loss: 0.2020 - val_accuracy: 0.9668\n",
      "Epoch 61/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5534 - accuracy: 0.8281\n",
      "Epoch 61: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.8175 - val_loss: 0.2063 - val_accuracy: 0.9712\n",
      "Epoch 62/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4611 - accuracy: 0.8047\n",
      "Epoch 62: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.8262 - val_loss: 0.2043 - val_accuracy: 0.9721\n",
      "Epoch 63/1000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8205\n",
      "Epoch 63: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.8205 - val_loss: 0.2018 - val_accuracy: 0.9704\n",
      "Epoch 64/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5644 - accuracy: 0.7656\n",
      "Epoch 64: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8235 - val_loss: 0.1981 - val_accuracy: 0.9695\n",
      "Epoch 65/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3919 - accuracy: 0.8672\n",
      "Epoch 65: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.8274 - val_loss: 0.1968 - val_accuracy: 0.9704\n",
      "Epoch 66/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4332 - accuracy: 0.8359\n",
      "Epoch 66: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8358 - val_loss: 0.1939 - val_accuracy: 0.9730\n",
      "Epoch 67/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4401 - accuracy: 0.8359\n",
      "Epoch 67: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.8226 - val_loss: 0.1969 - val_accuracy: 0.9712\n",
      "Epoch 68/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4809 - accuracy: 0.8281\n",
      "Epoch 68: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8325 - val_loss: 0.1906 - val_accuracy: 0.9739\n",
      "Epoch 69/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4618 - accuracy: 0.8281\n",
      "Epoch 69: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8283 - val_loss: 0.1846 - val_accuracy: 0.9784\n",
      "Epoch 70/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4335 - accuracy: 0.8281\n",
      "Epoch 70: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8352 - val_loss: 0.1924 - val_accuracy: 0.9721\n",
      "Epoch 71/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3967 - accuracy: 0.8672\n",
      "Epoch 71: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8379 - val_loss: 0.1969 - val_accuracy: 0.9757\n",
      "Epoch 72/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3820 - accuracy: 0.8203\n",
      "Epoch 72: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8277 - val_loss: 0.1912 - val_accuracy: 0.9739\n",
      "Epoch 73/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3126 - accuracy: 0.8750\n",
      "Epoch 73: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8280 - val_loss: 0.1846 - val_accuracy: 0.9757\n",
      "Epoch 74/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5364 - accuracy: 0.8125\n",
      "Epoch 74: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8223 - val_loss: 0.1829 - val_accuracy: 0.9739\n",
      "Epoch 75/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3211 - accuracy: 0.9062\n",
      "Epoch 75: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8373 - val_loss: 0.1826 - val_accuracy: 0.9730\n",
      "Epoch 76/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3478 - accuracy: 0.8516\n",
      "Epoch 76: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8376 - val_loss: 0.1811 - val_accuracy: 0.9730\n",
      "Epoch 77/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4014 - accuracy: 0.8672\n",
      "Epoch 77: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8328 - val_loss: 0.1807 - val_accuracy: 0.9784\n",
      "Epoch 78/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3805 - accuracy: 0.8750\n",
      "Epoch 78: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8322 - val_loss: 0.1781 - val_accuracy: 0.9757\n",
      "Epoch 79/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5119 - accuracy: 0.7734\n",
      "Epoch 79: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8226 - val_loss: 0.1791 - val_accuracy: 0.9766\n",
      "Epoch 80/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5257 - accuracy: 0.8438\n",
      "Epoch 80: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8358 - val_loss: 0.1763 - val_accuracy: 0.9775\n",
      "Epoch 81/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5596 - accuracy: 0.8047\n",
      "Epoch 81: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8292 - val_loss: 0.1805 - val_accuracy: 0.9775\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4548 - accuracy: 0.8203\n",
      "Epoch 82: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8346 - val_loss: 0.1880 - val_accuracy: 0.9793\n",
      "Epoch 83/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5163 - accuracy: 0.8047\n",
      "Epoch 83: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8316 - val_loss: 0.1836 - val_accuracy: 0.9811\n",
      "Epoch 84/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3602 - accuracy: 0.8672\n",
      "Epoch 84: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8451 - val_loss: 0.1879 - val_accuracy: 0.9757\n",
      "Epoch 85/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4111 - accuracy: 0.8516\n",
      "Epoch 85: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8337 - val_loss: 0.1795 - val_accuracy: 0.9793\n",
      "Epoch 86/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4779 - accuracy: 0.7812\n",
      "Epoch 86: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8424 - val_loss: 0.1848 - val_accuracy: 0.9784\n",
      "Epoch 87/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3251 - accuracy: 0.8984\n",
      "Epoch 87: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8319 - val_loss: 0.1826 - val_accuracy: 0.9802\n",
      "Epoch 88/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3676 - accuracy: 0.8750\n",
      "Epoch 88: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8436 - val_loss: 0.1853 - val_accuracy: 0.9775\n",
      "Epoch 89/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5753 - accuracy: 0.7812\n",
      "Epoch 89: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8409 - val_loss: 0.1789 - val_accuracy: 0.9784\n",
      "Epoch 90/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4153 - accuracy: 0.8203\n",
      "Epoch 90: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8472 - val_loss: 0.1819 - val_accuracy: 0.9784\n",
      "Epoch 91/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4646 - accuracy: 0.7891\n",
      "Epoch 91: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8295 - val_loss: 0.1791 - val_accuracy: 0.9784\n",
      "Epoch 92/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4186 - accuracy: 0.8672\n",
      "Epoch 92: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8418 - val_loss: 0.1715 - val_accuracy: 0.9811\n",
      "Epoch 93/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.2935 - accuracy: 0.9375\n",
      "Epoch 93: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8361 - val_loss: 0.1786 - val_accuracy: 0.9820\n",
      "Epoch 94/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3364 - accuracy: 0.8594\n",
      "Epoch 94: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8490 - val_loss: 0.1739 - val_accuracy: 0.9820\n",
      "Epoch 95/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5169 - accuracy: 0.7969\n",
      "Epoch 95: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8436 - val_loss: 0.1800 - val_accuracy: 0.9829\n",
      "Epoch 96/1000\n",
      "20/27 [=====================>........] - ETA: 0s - loss: 0.3981 - accuracy: 0.8531\n",
      "Epoch 96: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8463 - val_loss: 0.1789 - val_accuracy: 0.9820\n",
      "Epoch 97/1000\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 0.4142 - accuracy: 0.8494\n",
      "Epoch 97: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8514 - val_loss: 0.1728 - val_accuracy: 0.9820\n",
      "Epoch 98/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3744 - accuracy: 0.8516\n",
      "Epoch 98: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8328 - val_loss: 0.1774 - val_accuracy: 0.9793\n",
      "Epoch 99/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4196 - accuracy: 0.8516\n",
      "Epoch 99: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8430 - val_loss: 0.1844 - val_accuracy: 0.9784\n",
      "Epoch 100/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3347 - accuracy: 0.8516\n",
      "Epoch 100: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8415 - val_loss: 0.1842 - val_accuracy: 0.9793\n",
      "Epoch 101/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3316 - accuracy: 0.8750\n",
      "Epoch 101: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8493 - val_loss: 0.1789 - val_accuracy: 0.9793\n",
      "Epoch 102/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3145 - accuracy: 0.8672\n",
      "Epoch 102: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8487 - val_loss: 0.1737 - val_accuracy: 0.9802\n",
      "Epoch 103/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4173 - accuracy: 0.8047\n",
      "Epoch 103: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8403 - val_loss: 0.1643 - val_accuracy: 0.9829\n",
      "Epoch 104/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4300 - accuracy: 0.8359\n",
      "Epoch 104: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8343 - val_loss: 0.1735 - val_accuracy: 0.9802\n",
      "Epoch 105/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4039 - accuracy: 0.8516\n",
      "Epoch 105: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8451 - val_loss: 0.1850 - val_accuracy: 0.9793\n",
      "Epoch 106/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8516\n",
      "Epoch 106: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8394 - val_loss: 0.1814 - val_accuracy: 0.9838\n",
      "Epoch 107/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4325 - accuracy: 0.7891\n",
      "Epoch 107: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8430 - val_loss: 0.1716 - val_accuracy: 0.9838\n",
      "Epoch 108/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3778 - accuracy: 0.8516\n",
      "Epoch 108: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8409 - val_loss: 0.1792 - val_accuracy: 0.9811\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4863 - accuracy: 0.8438\n",
      "Epoch 109: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8472 - val_loss: 0.1810 - val_accuracy: 0.9811\n",
      "Epoch 110/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4374 - accuracy: 0.8516\n",
      "Epoch 110: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8472 - val_loss: 0.1737 - val_accuracy: 0.9802\n",
      "Epoch 111/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4029 - accuracy: 0.8480\n",
      "Epoch 111: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8481 - val_loss: 0.1660 - val_accuracy: 0.9829\n",
      "Epoch 112/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3851 - accuracy: 0.8438\n",
      "Epoch 112: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8403 - val_loss: 0.1677 - val_accuracy: 0.9847\n",
      "Epoch 113/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4244 - accuracy: 0.8359\n",
      "Epoch 113: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8502 - val_loss: 0.1748 - val_accuracy: 0.9784\n",
      "Epoch 114/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4321 - accuracy: 0.8359\n",
      "Epoch 114: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8448 - val_loss: 0.1669 - val_accuracy: 0.9829\n",
      "Epoch 115/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4610 - accuracy: 0.8516\n",
      "Epoch 115: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8343 - val_loss: 0.1734 - val_accuracy: 0.9838\n",
      "Epoch 116/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5233 - accuracy: 0.8047\n",
      "Epoch 116: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8487 - val_loss: 0.1737 - val_accuracy: 0.9829\n",
      "Epoch 117/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5147 - accuracy: 0.8281\n",
      "Epoch 117: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8604 - val_loss: 0.1699 - val_accuracy: 0.9829\n",
      "Epoch 118/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4618 - accuracy: 0.8359\n",
      "Epoch 118: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8475 - val_loss: 0.1736 - val_accuracy: 0.9793\n",
      "Epoch 119/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4483 - accuracy: 0.8047\n",
      "Epoch 119: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8445 - val_loss: 0.1670 - val_accuracy: 0.9847\n",
      "Epoch 120/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3563 - accuracy: 0.8359\n",
      "Epoch 120: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8580 - val_loss: 0.1680 - val_accuracy: 0.9847\n",
      "Epoch 121/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5385 - accuracy: 0.7812\n",
      "Epoch 121: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8478 - val_loss: 0.1641 - val_accuracy: 0.9829\n",
      "Epoch 122/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3826 - accuracy: 0.8516\n",
      "Epoch 122: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8406 - val_loss: 0.1681 - val_accuracy: 0.9874\n",
      "Epoch 123/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3644 - accuracy: 0.8594\n",
      "Epoch 123: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8625 - val_loss: 0.1633 - val_accuracy: 0.9865\n",
      "Epoch 124/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3676 - accuracy: 0.8438\n",
      "Epoch 124: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8523 - val_loss: 0.1656 - val_accuracy: 0.9838\n",
      "Epoch 125/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3408 - accuracy: 0.8359\n",
      "Epoch 125: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8547 - val_loss: 0.1656 - val_accuracy: 0.9838\n",
      "Epoch 126/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4644 - accuracy: 0.7812\n",
      "Epoch 126: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8523 - val_loss: 0.1672 - val_accuracy: 0.9838\n",
      "Epoch 127/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3829 - accuracy: 0.8438\n",
      "Epoch 127: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8511 - val_loss: 0.1711 - val_accuracy: 0.9811\n",
      "Epoch 128/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3755 - accuracy: 0.8672\n",
      "Epoch 128: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8508 - val_loss: 0.1786 - val_accuracy: 0.9793\n",
      "Epoch 129/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3711 - accuracy: 0.8612\n",
      "Epoch 129: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8613 - val_loss: 0.1733 - val_accuracy: 0.9802\n",
      "Epoch 130/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3080 - accuracy: 0.8750\n",
      "Epoch 130: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8478 - val_loss: 0.1644 - val_accuracy: 0.9829\n",
      "Epoch 131/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4279 - accuracy: 0.8516\n",
      "Epoch 131: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8529 - val_loss: 0.1731 - val_accuracy: 0.9856\n",
      "Epoch 132/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3332 - accuracy: 0.9141\n",
      "Epoch 132: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8571 - val_loss: 0.1673 - val_accuracy: 0.9847\n",
      "Epoch 133/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3760 - accuracy: 0.8438\n",
      "Epoch 133: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8478 - val_loss: 0.1746 - val_accuracy: 0.9829\n",
      "Epoch 134/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3855 - accuracy: 0.8750\n",
      "Epoch 134: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8535 - val_loss: 0.1758 - val_accuracy: 0.9838\n",
      "Epoch 135/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4557 - accuracy: 0.8203\n",
      "Epoch 135: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8550 - val_loss: 0.1639 - val_accuracy: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4030 - accuracy: 0.8359\n",
      "Epoch 136: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8481 - val_loss: 0.1601 - val_accuracy: 0.9838\n",
      "Epoch 137/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3593 - accuracy: 0.8672\n",
      "Epoch 137: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8508 - val_loss: 0.1737 - val_accuracy: 0.9802\n",
      "Epoch 138/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3933 - accuracy: 0.8438\n",
      "Epoch 138: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8657 - val_loss: 0.1716 - val_accuracy: 0.9811\n",
      "Epoch 139/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3351 - accuracy: 0.8594\n",
      "Epoch 139: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8565 - val_loss: 0.1697 - val_accuracy: 0.9811\n",
      "Epoch 140/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3466 - accuracy: 0.8828\n",
      "Epoch 140: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8651 - val_loss: 0.1722 - val_accuracy: 0.9820\n",
      "Epoch 141/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.2612 - accuracy: 0.9141\n",
      "Epoch 141: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8577 - val_loss: 0.1735 - val_accuracy: 0.9829\n",
      "Epoch 142/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3626 - accuracy: 0.8594\n",
      "Epoch 142: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8340 - val_loss: 0.1724 - val_accuracy: 0.9829\n",
      "Epoch 143/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3708 - accuracy: 0.8516\n",
      "Epoch 143: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8499 - val_loss: 0.1726 - val_accuracy: 0.9802\n",
      "Epoch 144/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3876 - accuracy: 0.8594\n",
      "Epoch 144: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8526 - val_loss: 0.1735 - val_accuracy: 0.9820\n",
      "Epoch 145/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4220 - accuracy: 0.8359\n",
      "Epoch 145: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8523 - val_loss: 0.1726 - val_accuracy: 0.9829\n",
      "Epoch 146/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.2609 - accuracy: 0.9219\n",
      "Epoch 146: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8511 - val_loss: 0.1787 - val_accuracy: 0.9802\n",
      "Epoch 147/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8750\n",
      "Epoch 147: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8565 - val_loss: 0.1804 - val_accuracy: 0.9829\n",
      "Epoch 148/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3186 - accuracy: 0.8672\n",
      "Epoch 148: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8517 - val_loss: 0.1824 - val_accuracy: 0.9829\n",
      "Epoch 149/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.2393 - accuracy: 0.9219\n",
      "Epoch 149: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8622 - val_loss: 0.1645 - val_accuracy: 0.9829\n",
      "Epoch 150/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3837 - accuracy: 0.8594\n",
      "Epoch 150: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8538 - val_loss: 0.1652 - val_accuracy: 0.9820\n",
      "Epoch 151/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4083 - accuracy: 0.8281\n",
      "Epoch 151: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8478 - val_loss: 0.1722 - val_accuracy: 0.9811\n",
      "Epoch 152/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3651 - accuracy: 0.8828\n",
      "Epoch 152: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8541 - val_loss: 0.1789 - val_accuracy: 0.9820\n",
      "Epoch 153/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3341 - accuracy: 0.8984\n",
      "Epoch 153: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8595 - val_loss: 0.1833 - val_accuracy: 0.9784\n",
      "Epoch 154/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3166 - accuracy: 0.8672\n",
      "Epoch 154: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8631 - val_loss: 0.1786 - val_accuracy: 0.9784\n",
      "Epoch 155/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4370 - accuracy: 0.8672\n",
      "Epoch 155: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8508 - val_loss: 0.1777 - val_accuracy: 0.9802\n",
      "Epoch 156/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4779 - accuracy: 0.8047\n",
      "Epoch 156: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8535 - val_loss: 0.1819 - val_accuracy: 0.9784\n",
      "Epoch 156: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219e556dd90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "[0.6954564  0.21683562 0.08770806]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 747us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       410\n",
      "           1       0.98      0.97      0.97       385\n",
      "           2       0.95      0.98      0.97       318\n",
      "\n",
      "    accuracy                           0.98      1113\n",
      "   macro avg       0.98      0.98      0.98      1113\n",
      "weighted avg       0.98      0.98      0.98      1113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\asus\\AppData\\Local\\Temp\\tmpw8um84si\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\asus\\AppData\\Local\\Temp\\tmpw8um84si\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69545656 0.2168354  0.08770802]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "from utils import CvFpsCalc\n",
    "from model import KeyPointClassifier\n",
    "from model import PointHistoryClassifier\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--device\", type=int, default=0)\n",
    "    parser.add_argument(\"--width\", help='cap width', type=int, default=960)\n",
    "    parser.add_argument(\"--height\", help='cap height', type=int, default=540)\n",
    "\n",
    "    parser.add_argument('--use_static_image_mode', action='store_true')\n",
    "    parser.add_argument(\"--min_detection_confidence\",\n",
    "                        help='min_detection_confidence',\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "    parser.add_argument(\"--min_tracking_confidence\",\n",
    "                        help='min_tracking_confidence',\n",
    "                        type=int,\n",
    "                        default=0.5)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 引数解析 #################################################################\n",
    "    args = get_args()\n",
    "\n",
    "    cap_device = args.device\n",
    "    cap_width = args.width\n",
    "    cap_height = args.height\n",
    "\n",
    "    use_static_image_mode = args.use_static_image_mode\n",
    "    min_detection_confidence = args.min_detection_confidence\n",
    "    min_tracking_confidence = args.min_tracking_confidence\n",
    "\n",
    "    use_brect = True\n",
    "\n",
    "    # カメラ準備 ###############################################################\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "\n",
    "    # モデルロード #############################################################\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=use_static_image_mode,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    )\n",
    "\n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "    point_history_classifier = PointHistoryClassifier()\n",
    "\n",
    "    # ラベル読み込み ###########################################################\n",
    "    with open('model/keypoint_classifier/keypoint_classifier_label.csv',\n",
    "              encoding='utf-8-sig') as f:\n",
    "        keypoint_classifier_labels = csv.reader(f)\n",
    "        keypoint_classifier_labels = [\n",
    "            row[0] for row in keypoint_classifier_labels\n",
    "        ]\n",
    "    with open(\n",
    "            'model/point_history_classifier/point_history_classifier_label.csv',\n",
    "            encoding='utf-8-sig') as f:\n",
    "        point_history_classifier_labels = csv.reader(f)\n",
    "        point_history_classifier_labels = [\n",
    "            row[0] for row in point_history_classifier_labels\n",
    "        ]\n",
    "\n",
    "    # FPS計測モジュール ########################################################\n",
    "    cvFpsCalc = CvFpsCalc(buffer_len=10)\n",
    "\n",
    "    # 座標履歴 #################################################################\n",
    "    history_length = 16\n",
    "    point_history = deque(maxlen=history_length)\n",
    "\n",
    "    # フィンガージェスチャー履歴 ################################################\n",
    "    finger_gesture_history = deque(maxlen=history_length)\n",
    "\n",
    "    #  ########################################################################\n",
    "    mode = 0\n",
    "\n",
    "    while True:\n",
    "        fps = cvFpsCalc.get()\n",
    "\n",
    "        # キー処理(ESC：終了) #################################################\n",
    "        key = cv.waitKey(10)\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        number, mode = select_mode(key, mode)\n",
    "\n",
    "        # カメラキャプチャ #####################################################\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv.flip(image, 1)  # ミラー表示\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        # 検出実施 #############################################################\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        #  ####################################################################\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                  results.multi_handedness):\n",
    "                # 外接矩形の計算\n",
    "                brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                # ランドマークの計算\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                # 相対座標・正規化座標への変換\n",
    "                pre_processed_landmark_list = pre_process_landmark(\n",
    "                    landmark_list)\n",
    "                pre_processed_point_history_list = pre_process_point_history(\n",
    "                    debug_image, point_history)\n",
    "                # 学習データ保存\n",
    "                logging_csv(number, mode, pre_processed_landmark_list,\n",
    "                            pre_processed_point_history_list)\n",
    "\n",
    "                # ハンドサイン分類\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "                if hand_sign_id == 2:  # 指差しサイン\n",
    "                    point_history.append(landmark_list[8])  # 人差指座標\n",
    "                else:\n",
    "                    point_history.append([0, 0])\n",
    "\n",
    "                # フィンガージェスチャー分類\n",
    "                finger_gesture_id = 0\n",
    "                point_history_len = len(pre_processed_point_history_list)\n",
    "                if point_history_len == (history_length * 2):\n",
    "                    finger_gesture_id = point_history_classifier(\n",
    "                        pre_processed_point_history_list)\n",
    "\n",
    "                # 直近検出の中で最多のジェスチャーIDを算出\n",
    "                finger_gesture_history.append(finger_gesture_id)\n",
    "                most_common_fg_id = Counter(\n",
    "                    finger_gesture_history).most_common()\n",
    "\n",
    "                # 描画\n",
    "                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                debug_image = draw_info_text(\n",
    "                    debug_image,\n",
    "                    brect,\n",
    "                    handedness,\n",
    "                    keypoint_classifier_labels[hand_sign_id],\n",
    "                    point_history_classifier_labels[most_common_fg_id[0][0]],\n",
    "                )\n",
    "        else:\n",
    "            point_history.append([0, 0])\n",
    "\n",
    "        debug_image = draw_point_history(debug_image, point_history)\n",
    "        debug_image = draw_info(debug_image, fps, mode, number)\n",
    "\n",
    "        # 画面反映 #############################################################\n",
    "        cv.imshow('Hand Gesture Recognition', debug_image)\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "def select_mode(key, mode):\n",
    "    number = -1\n",
    "    if 48 <= key <= 57:  # 0 ~ 9\n",
    "        number = key - 48\n",
    "    if key == 110:  # n\n",
    "        mode = 0\n",
    "    if key == 107:  # k\n",
    "        mode = 1\n",
    "    if key == 104:  # h\n",
    "        mode = 2\n",
    "    return number, mode\n",
    "\n",
    "\n",
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # キーポイント\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # 相対座標に変換\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # 1次元リストに変換\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # 正規化\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def pre_process_point_history(image, point_history):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    temp_point_history = copy.deepcopy(point_history)\n",
    "\n",
    "    # 相対座標に変換\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, point in enumerate(temp_point_history):\n",
    "        if index == 0:\n",
    "            base_x, base_y = point[0], point[1]\n",
    "\n",
    "        temp_point_history[index][0] = (temp_point_history[index][0] -\n",
    "                                        base_x) / image_width\n",
    "        temp_point_history[index][1] = (temp_point_history[index][1] -\n",
    "                                        base_y) / image_height\n",
    "\n",
    "    # 1次元リストに変換\n",
    "    temp_point_history = list(\n",
    "        itertools.chain.from_iterable(temp_point_history))\n",
    "\n",
    "    return temp_point_history\n",
    "\n",
    "\n",
    "def logging_csv(number, mode, landmark_list, point_history_list):\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and (0 <= number <= 9):\n",
    "        csv_path = 'model/keypoint_classifier/keypoint.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *landmark_list])\n",
    "    if mode == 2 and (0 <= number <= 9):\n",
    "        csv_path = 'model/point_history_classifier/point_history.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *point_history_list])\n",
    "    return\n",
    "\n",
    "\n",
    "def draw_landmarks(image, landmark_point):\n",
    "    # 接続線\n",
    "    if len(landmark_point) > 0:\n",
    "        # 親指\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # 人差指\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # 中指\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # 薬指\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # 小指\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # 手の平\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "    # キーポイント\n",
    "    for index, landmark in enumerate(landmark_point):\n",
    "        if index == 0:  # 手首1\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 1:  # 手首2\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 2:  # 親指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 3:  # 親指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 4:  # 親指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 5:  # 人差指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 6:  # 人差指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 7:  # 人差指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 8:  # 人差指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 9:  # 中指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 10:  # 中指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 11:  # 中指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 12:  # 中指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 13:  # 薬指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 14:  # 薬指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 15:  # 薬指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 16:  # 薬指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 17:  # 小指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 18:  # 小指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 19:  # 小指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 20:  # 小指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # 外接矩形\n",
    "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text,\n",
    "                   finger_gesture_text):\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (0, 0, 0), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    if finger_gesture_text != \"\":\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,\n",
    "                   cv.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_point_history(image, point_history):\n",
    "    for index, point in enumerate(point_history):\n",
    "        if point[0] != 0 and point[1] != 0:\n",
    "            cv.circle(image, (point[0], point[1]), 1 + int(index / 2),\n",
    "                      (152, 251, 152), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info(image, fps, mode, number):\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (255, 255, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    mode_string = ['Logging Key Point', 'Logging Point History']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv.putText(image, \"MODE:\" + mode_string[mode - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if 0 <= number <= 9:\n",
    "            cv.putText(image, \"NUM:\" + str(number), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
